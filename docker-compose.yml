version: '3.8'

services:
  # Database
  database:
    container_name: database
    image: postgres:latest
    networks:
      - cluster_interface
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=postgres
    volumes:
      - ./simulate/database:/var/lib/postgresql/data

  # Dashboard (Streamlit + Plotly)
  dashboard:
    container_name: dashboard
    build: ./simulate/dashboard
    ports:
      - "8501:8501"
    environment:
      - DB_HOST=database
      - DB_PORT=5432
      - DB_NAME=postgres
      - DB_USER=postgres
      - DB_PASSWORD=postgres
    depends_on:
      - database
    networks:
      - cluster_interface

  # Backend
  backend:
    container_name: backend
    build: ./simulate/backend
    networks:
      - cluster_interface
    ports:
      - "8000:8000"
    environment:
      - DB_HOST=database
      - DB_USER=postgres
      - DB_PASSWORD=postgres
      - DB_NAME=postgres
    volumes:
      - ./simulate/backend:/app/log
    depends_on:
      - database

  # Federated Server
  fed_server:
    container_name: fedserver
    build: ./simulate/fedserver
    networks:
      - cluster_interface
    ports:
      - "8001:8000"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    environment:
      - BACKEND_URL=http://host.docker.internal:8000
      - FED_SERVER_ID=fed_server
      - FED_SERVER_IP=host.docker.internal:8001
    depends_on:
    - backend

  # Split Federated Server
  split_server:
    container_name: splitserver
    build: ./simulate/splitserver
    networks:
      - cluster_interface
    ports:
      - "8002:8000"
    volumes:
      - ./simulate/splitserver:/app/
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    environment:
      - BACKEND_URL=http://host.docker.internal:8000
      - SPLIT_SERVER_ID=split_server
      - SPLIT_SERVER_IP=host.docker.internal:8002
      - NVIDIA_VISIBLE_DEVICES=all
    depends_on:
    - backend

  # Clients 1â€“5
  client1:
    container_name: client1
    build: ./simulate/client
    networks:
      - cluster_interface
    ports:
      - "8005:8000"
    environment:
      - BACKEND_URL=http://host.docker.internal:8000
      - CLIENT_ID=1
      - CLIENT_IP=host.docker.internal:8005
      - SPLIT_SERVER=http://host.docker.internal:8000
      - FED_SERVER=http://host.docker.internal:8001
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ./simulate/volumes/client1:/app/data/
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    depends_on:
    - backend

  client2:
    container_name: client2
    build: ./simulate/client
    networks:
      - cluster_interface
    ports:
      - "8006:8000"
    environment:
      - BACKEND_URL=http://host.docker.internal:8000
      - CLIENT_ID=2
      - CLIENT_IP=host.docker.internal:8006
      - SPLIT_SERVER=http://host.docker.internal:8000
      - FED_SERVER=http://host.docker.internal:8001
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ./simulate/volumes/client2:/app/data/
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    depends_on:
    - backend

  client3:
    container_name: client3
    build: ./simulate/client
    networks:
      - cluster_interface
    ports:
      - "8007:8000"
    environment:
      - BACKEND_URL=http://host.docker.internal:8000
      - CLIENT_ID=3
      - CLIENT_IP=host.docker.internal:8007
      - SPLIT_SERVER=http://host.docker.internal:8000
      - FED_SERVER=http://host.docker.internal:8001
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ./simulate/volumes/client3:/app/data/
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    depends_on:
    - backend

  client4:
    container_name: client4
    build: ./simulate/client
    networks:
      - cluster_interface
    ports:
      - "8008:8000"
    environment:
      - BACKEND_URL=http://host.docker.internal:8000
      - CLIENT_ID=4
      - CLIENT_IP=host.docker.internal:8008
      - SPLIT_SERVER=http://host.docker.internal:8000
      - FED_SERVER=http://host.docker.internal:8001
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ./simulate/volumes/client4:/app/data/
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    depends_on:
    - backend

  client5:
    container_name: client5
    build: ./simulate/client
    networks:
      - cluster_interface
    ports:
      - "8009:8000"
    environment:
      - BACKEND_URL=http://host.docker.internal:8000
      - CLIENT_ID=5
      - CLIENT_IP=host.docker.internal:8009
      - SPLIT_SERVER=http://host.docker.internal:8000
      - FED_SERVER=http://host.docker.internal:8001
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ./simulate/volumes/client5:/app/data/
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    depends_on:
    - backend

  # client6:
  #   container_name: client6
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8010:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=6
  #     - CLIENT_IP=host.docker.internal:8010
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client6:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

  # client7:
  #   container_name: client7
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8011:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=7
  #     - CLIENT_IP=host.docker.internal:8011
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client7:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

  # client8:
  #   container_name: client8
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8012:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=8
  #     - CLIENT_IP=host.docker.internal:8012
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client8:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

  # client9:
  #   container_name: client9
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8013:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=9
  #     - CLIENT_IP=host.docker.internal:8013
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client9:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

  # client10:
  #   container_name: client10
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8014:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=10
  #     - CLIENT_IP=host.docker.internal:8014
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client10:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

  # client11:
  #   container_name: client11
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8015:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=11
  #     - CLIENT_IP=host.docker.internal:8015
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client11:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

  # client12:
  #   container_name: client12
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8016:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=12
  #     - CLIENT_IP=host.docker.internal:8016
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client12:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

  # client13:
  #   container_name: client13
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8017:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=13
  #     - CLIENT_IP=host.docker.internal:8017
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client13:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

  # client14:
  #   container_name: client14
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8018:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=14
  #     - CLIENT_IP=host.docker.internal:8018
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client14:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

  # client15:
  #   container_name: client15
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8019:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=15
  #     - CLIENT_IP=host.docker.internal:8019
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client15:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

  # client16:
  #   container_name: client16
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8020:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=16
  #     - CLIENT_IP=host.docker.internal:8020
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client16:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

  # client17:
  #   container_name: client17
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8021:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=17
  #     - CLIENT_IP=host.docker.internal:8021
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client17:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

  # client18:
  #   container_name: client18
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8022:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=18
  #     - CLIENT_IP=host.docker.internal:8022
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client18:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

  # client19:
  #   container_name: client19
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8023:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=19
  #     - CLIENT_IP=host.docker.internal:8023
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client19:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

  # client20:
  #   container_name: client20
  #   build: ./simulate/client
  #   networks:
  #     - cluster_interface
  #   ports:
  #     - "8024:8000"
  #   environment:
  #     - BACKEND_URL=http://host.docker.internal:8000
  #     - CLIENT_ID=20
  #     - CLIENT_IP=host.docker.internal:8024
  #     - SPLIT_SERVER=http://host.docker.internal:8000
  #     - FED_SERVER=http://host.docker.internal:8001
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   volumes:
  #     - ./simulate/volumes/client20:/app/data/
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   depends_on:
  #     - backend

networks:
  cluster_interface:
    driver: bridge